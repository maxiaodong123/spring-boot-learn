#spring:
#  redis:
#    cluster:
#      #设置key的生存时间，当key过期时，它会被自动删除；
#      expire-seconds: 120
#      #设置命令的执行时间，如果超过这个时间，则报错;
#      command-timeout: 5000
#      #设置redis集群的节点信息，其中namenode为域名解析，通过解析域名来获取相应的地址;
#      nodes: 10.3.1.5:9801,10.3.1.5:9802,10.3.1.5:9803,10.3.1.5:9804,10.3.1.5:9805,10.3.1.5:9806

server:
  port: 8085

spring:
  # kafka集群配置 ,bootstrap-servers 是必须的
  kafka:
    # 生产者的kafka集群地址
    bootstrap-servers: 114.117.165.214:9002,114.117.165.214:9003,114.117.165.214:9004
    # Kafka Producer 配置项
    producer:
      acks: 1 # 0-不应答。1-leader 应答。all-所有 leader 和 follower 应答。
      retries: 3 # 发送失败时，重试发送的次数
      key-serializer: org.apache.kafka.common.serialization.StringSerializer # 消息的 key 的序列化
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer # 消息的 value 的序列化
    # Kafka Consumer 配置项
    consumer:
      auto-offset-reset: earliest # 设置消费者分组最初的消费进度为 earliest 。可参考博客 https://blog.csdn.net/lishuangzhe7047/article/details/74530417 理解
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        spring:
          json:
            trusted:
              packages: cn.iocoder.springboot.lab03.kafkademo.message
    # Kafka Consumer Listener 监听器配置
    listener:
      missing-topics-fatal: false # 消费监听接口监听的主题不存在时，默认会报错。所以通过设置为 false ，解决报错


logging:
  level:
    org:
      springframework:
        kafka: ERROR # spring-kafka INFO 日志太多了，所以我们限制只打印 ERROR 级别
      apache:
        kafka: ERROR # kafka INFO 日志太多了，所以我们限制只打印 ERROR 级别